# 根据拓扑分配IP地址

## 大面儿

为不同的拓扑区域分配从IP池中分配不同的IP地址块。

## 价值

如果你的工作负载分布在不同的地域、区域、机架，你可能想让它们都从同一个IP池中获取IP地址。这种策略有助于减少网络中的路由数量，或者是满足外部防火墙设备或策略的一些要求。Calico可以为IP池资源配置节点标签和节点选择器来轻松实现这种场景。

## 特性

本文使用以下Calico特性：

- **IPPool**资源

## 概念

### IP地址分配

基于拓扑的IP地址分配需要按主机（节点）来做地址。因此无法使用Kubernetes的注解，因为它们都是按命名空间或者按Pod来的。尽管你可以在CNI配置中为节点配置IP地址，但你那是修改了主机的文件系统。最好的方法应该是使用IP池的node-selection IP地址分配。

### Node-selectionIP地址分配

基于节点选择的IP地址分配的意思就是字面意思：设置节点标签，Calico给节点分配IP时使用节点选择器来决定使用哪些IP池子。

### 最佳实践

节点给工作负载分配的地址来自选中该节点的IP池子。为了避免工作负载拿不到IP导致起不来，保证所有节点都被至少一个IP池子选中就显得尤为重要。

## 怎么弄

### 创建一个IP池，指定节点

在下面的例子中，我们创建了一个IP池，它只会为那些带有**zone=west**标签的节点分配IP地址。

```yaml
apiVersion: projectcalico.org/v3
kind: IPPool
metadata:
   name: zone-west-ippool
spec:
   cidr: 192.168.0.0/24
   ipipMode: Always
   natOutgoing: true
   nodeSelector: zone == "west"
```

然后我们找一个节点打上zone=west标签。例如：

```shell
$ kubectl label nodes kube-node-0 zone=west
```

## 教程

这里我们创建一个两机架四节点的集群（2节点/机架）。

```text
       -------------------
       |    router       |
       -------------------
       |                 |
---------------   ---------------
| rack-0      |   | rack-1      |
---------------   ---------------
| kube-node-0 |   | kube-node-2 |
- - - - - - - -   - - - - - - - -
| kube-node-1 |   | kube-node-3 |
- - - - - - - -   - - - - - - - -
```

使用的Pod IP范围是`192.168.0.0/16`，我们主要关注以下内容：为`rack-0`和`rack-1`分别保留`192.168.0.0/24`和`192.168.1.0/24`。说干就干。

安装Calico的时候如果没有指定默认的IP池，执行`calicoctl get ippool -o wide`可以看到Calico创建了默认的IP池`192.168.0.0/16`：

```text
NAME                  CIDR             NAT    IPIPMODE   DISABLED   SELECTOR
default-ipv4-ippool   192.168.0.0/16   true   Always     false      all()
```

1. 删除默认的IP池。

因为已有的`default-ipv4-ippool`占用了整个`/16`的块，我们首先要删掉它：

```shell
$ calicoctl delete ippools default-ipv4-ippool
```

2. 打标签

要想将IP池分配给特定的节点，这些节点必须打上[Kubernetes标签](https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes/#add-a-label-to-a-node)。

```shell
$ kubectl label nodes kube-node-0 rack=0
$ kubectl label nodes kube-node-1 rack=0
$ kubectl label nodes kube-node-2 rack=1
$ kubectl label nodes kube-node-3 rack=1
```

3. 给每个机架创建IP池。

```yaml
$ calicoctl create -f -<<EOF
apiVersion: projectcalico.org/v3
kind: IPPool
metadata:
  name: rack-0-ippool
spec:
  cidr: 192.168.0.0/24
  ipipMode: Always
  natOutgoing: true
  nodeSelector: rack == "0"
EOF
```

```yaml
$ calicoctl create -f -<<EOF
apiVersion: projectcalico.org/v3
kind: IPPool
metadata:
  name: rack-1-ippool
spec:
  cidr: 192.168.1.0/24
  ipipMode: Always
  natOutgoing: true
  nodeSelector: rack == "1"
EOF
```

执行`calicoctl get ippool -o wide`，我们会看到现在启用了两个IP池：

```text
NAME                  CIDR             NAT    IPIPMODE   DISABLED   SELECTOR
rack-0-ippool         192.168.0.0/24   true   Always     false      rack == "0"
rack-1-ippool         192.168.1.0/24   true   Always     false      rack == "1"
```

4. 确认IP池的节点选择器是否生效。

我们创建一个nginx的Deployment，五个副本，每个节点都有份儿。

```shell
$ kubectl run nginx --image nginx --replicas 5
```

执行`kubectl get pods -owide`，查看建好的工作负载的IP，都是来自机架对应的IP池。

```text
NAME                   READY   STATUS    RESTARTS   AGE    IP             NODE          NOMINATED NODE   READINESS GATES
nginx-5c7588df-prx4z   1/1     Running   0          6m3s   192.168.0.64   kube-node-0   <none>           <none>
nginx-5c7588df-s7qw6   1/1     Running   0          6m7s   192.168.0.129  kube-node-1   <none>           <none>
nginx-5c7588df-w7r7g   1/1     Running   0          6m3s   192.168.1.65   kube-node-2   <none>           <none>
nginx-5c7588df-62lnf   1/1     Running   0          6m3s   192.168.1.1    kube-node-3   <none>           <none>
nginx-5c7588df-pnsvv   1/1     Running   0          6m3s   192.168.1.64   kube-node-2   <none>           <none>
```

工作负载拿到的IP地址依赖于它们被调度到了哪个节点。而且，分配的地址都落在机架对应的IP池中。

> 注意：Calico IPAM不会为已经处于运行状态的工作负载重新分配IP地址。要想将正在运行的工作负载的IP地址更新成一个新建的池子中的地址，必须对它们进行重建。我们建议在正式投入生产之前完成这些操作，或者是在运维窗口内进行。